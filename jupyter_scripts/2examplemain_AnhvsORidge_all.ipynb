{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from folktables import ACSDataSource\n",
    "import folktables\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "from bestLS_hindsight import *\n",
    "from OnlineRidgeRiver import *\n",
    "from lean_adahedge import *\n",
    "import matplotlib.pyplot as plt\n",
    "from bestLS_hindsight_together import *\n",
    "from oridge_alwaysactive_implementable import *"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data for New Jersey in 2021 \n",
    "\n",
    "**X feature**\n",
    "\n",
    "    -The numeric features are AGEP: Age , WKHP: # of hours worked per week\n",
    "\n",
    "    -The categorical features are COW: Class of Worker, SEX: Male/Female, RAC1P - Race code, SCHL - Educational attainment, OCCP - Occupation code, MAR - Marital status\n",
    "\n",
    "**y target** \n",
    "\n",
    "    - is PINCP - Annual Income of the individual\n",
    "\n",
    "For more about these variable names search \"data dictionary\" for ACM PUMS 2021 at  https://www.census.gov/programs-surveys/acs/microdata/documentation.html\n",
    " \n",
    "The cell below loads a pandas dataframe in which we have already encoded categorical variables to one-hot, and scaled numeric variables by min-max scaling.\n",
    "\n",
    "To see how it was prepared see the **example_dataprocessing.ipynb** file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = pd.read_pickle(\"allstates2021.pkl\")\n",
    "#df_subset = pd.read_pickle(\"Name_of_subset_ofstates.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AGEP</th>\n",
       "      <th>WKHP</th>\n",
       "      <th>PINCP</th>\n",
       "      <th>COW_1</th>\n",
       "      <th>COW_2</th>\n",
       "      <th>COW_3</th>\n",
       "      <th>COW_4</th>\n",
       "      <th>COW_5</th>\n",
       "      <th>COW_6</th>\n",
       "      <th>COW_7</th>\n",
       "      <th>...</th>\n",
       "      <th>SEX_2</th>\n",
       "      <th>RAC1P_1</th>\n",
       "      <th>RAC1P_2</th>\n",
       "      <th>RAC1P_3</th>\n",
       "      <th>RAC1P_4</th>\n",
       "      <th>RAC1P_5</th>\n",
       "      <th>RAC1P_6</th>\n",
       "      <th>RAC1P_7</th>\n",
       "      <th>RAC1P_8</th>\n",
       "      <th>RAC1P_9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.025316</td>\n",
       "      <td>0.295918</td>\n",
       "      <td>0.039472</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.037975</td>\n",
       "      <td>0.397959</td>\n",
       "      <td>0.030967</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.025316</td>\n",
       "      <td>0.173469</td>\n",
       "      <td>0.030467</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.215190</td>\n",
       "      <td>0.051020</td>\n",
       "      <td>0.053479</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.025316</td>\n",
       "      <td>0.091837</td>\n",
       "      <td>0.009455</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1630162</th>\n",
       "      <td>0.291139</td>\n",
       "      <td>0.397959</td>\n",
       "      <td>0.399670</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1630163</th>\n",
       "      <td>0.379747</td>\n",
       "      <td>0.397959</td>\n",
       "      <td>0.299615</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1630164</th>\n",
       "      <td>0.367089</td>\n",
       "      <td>0.397959</td>\n",
       "      <td>0.092501</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1630165</th>\n",
       "      <td>0.063291</td>\n",
       "      <td>0.295918</td>\n",
       "      <td>0.060483</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1630166</th>\n",
       "      <td>0.493671</td>\n",
       "      <td>0.397959</td>\n",
       "      <td>0.138026</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1428283 rows × 301 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             AGEP      WKHP     PINCP  COW_1  COW_2  COW_3  COW_4  COW_5  \\\n",
       "0        0.025316  0.295918  0.039472      0      1      0      0      0   \n",
       "1        0.037975  0.397959  0.030967      1      0      0      0      0   \n",
       "2        0.025316  0.173469  0.030467      0      1      0      0      0   \n",
       "3        0.215190  0.051020  0.053479      0      1      0      0      0   \n",
       "4        0.025316  0.091837  0.009455      1      0      0      0      0   \n",
       "...           ...       ...       ...    ...    ...    ...    ...    ...   \n",
       "1630162  0.291139  0.397959  0.399670      1      0      0      0      0   \n",
       "1630163  0.379747  0.397959  0.299615      0      1      0      0      0   \n",
       "1630164  0.367089  0.397959  0.092501      0      0      0      1      0   \n",
       "1630165  0.063291  0.295918  0.060483      0      0      0      0      0   \n",
       "1630166  0.493671  0.397959  0.138026      0      1      0      0      0   \n",
       "\n",
       "         COW_6  COW_7  ...  SEX_2  RAC1P_1  RAC1P_2  RAC1P_3  RAC1P_4  \\\n",
       "0            0      0  ...      1        1        0        0        0   \n",
       "1            0      0  ...      0        0        1        0        0   \n",
       "2            0      0  ...      1        1        0        0        0   \n",
       "3            0      0  ...      1        1        0        0        0   \n",
       "4            0      0  ...      0        1        0        0        0   \n",
       "...        ...    ...  ...    ...      ...      ...      ...      ...   \n",
       "1630162      0      0  ...      1        0        0        0        0   \n",
       "1630163      0      0  ...      0        0        0        0        0   \n",
       "1630164      0      0  ...      1        0        0        0        0   \n",
       "1630165      1      0  ...      0        0        0        0        0   \n",
       "1630166      0      0  ...      1        0        1        0        0   \n",
       "\n",
       "         RAC1P_5  RAC1P_6  RAC1P_7  RAC1P_8  RAC1P_9  \n",
       "0              0        0        0        0        0  \n",
       "1              0        0        0        0        0  \n",
       "2              0        0        0        0        0  \n",
       "3              0        0        0        0        0  \n",
       "4              0        0        0        0        0  \n",
       "...          ...      ...      ...      ...      ...  \n",
       "1630162        0        0        0        0        1  \n",
       "1630163        0        0        0        0        1  \n",
       "1630164        0        0        0        0        1  \n",
       "1630165        0        0        0        0        1  \n",
       "1630166        0        0        0        0        0  \n",
       "\n",
       "[1428283 rows x 301 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dat = df_all.drop('PINCP', axis=1) #dropping the income column\n",
    "y_dat = pd.DataFrame(df_all['PINCP']) # picking up only the income column for the target"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SEX_1 is Male\n",
    "SEX_2 is Female\n",
    "RAC1P_1 is White\n",
    "RAC1P_2 is Black\n",
    "....\n",
    "See "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnames = ['SEX_1', 'SEX_2', 'RAC1P_1','RAC1P_2','RAC1P_3','RAC1P_4','RAC1P_5','RAC1P_6', 'RAC1P_7','RAC1P_8','RAC1P_9'] #sensitive group names\n",
    "sensitive_group_cols = X_dat[gnames] # this picks the above columns from X_dat dataframe\n",
    "A_tarr = sensitive_group_cols.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SEX_1</th>\n",
       "      <th>SEX_2</th>\n",
       "      <th>RAC1P_1</th>\n",
       "      <th>RAC1P_2</th>\n",
       "      <th>RAC1P_3</th>\n",
       "      <th>RAC1P_4</th>\n",
       "      <th>RAC1P_5</th>\n",
       "      <th>RAC1P_6</th>\n",
       "      <th>RAC1P_7</th>\n",
       "      <th>RAC1P_8</th>\n",
       "      <th>RAC1P_9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1630162</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1630163</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1630164</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1630165</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1630166</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1428283 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         SEX_1  SEX_2  RAC1P_1  RAC1P_2  RAC1P_3  RAC1P_4  RAC1P_5  RAC1P_6  \\\n",
       "0            0      1        1        0        0        0        0        0   \n",
       "1            1      0        0        1        0        0        0        0   \n",
       "2            0      1        1        0        0        0        0        0   \n",
       "3            0      1        1        0        0        0        0        0   \n",
       "4            1      0        1        0        0        0        0        0   \n",
       "...        ...    ...      ...      ...      ...      ...      ...      ...   \n",
       "1630162      0      1        0        0        0        0        0        0   \n",
       "1630163      1      0        0        0        0        0        0        0   \n",
       "1630164      0      1        0        0        0        0        0        0   \n",
       "1630165      1      0        0        0        0        0        0        0   \n",
       "1630166      0      1        0        1        0        0        0        0   \n",
       "\n",
       "         RAC1P_7  RAC1P_8  RAC1P_9  \n",
       "0              0        0        0  \n",
       "1              0        0        0  \n",
       "2              0        0        0  \n",
       "3              0        0        0  \n",
       "4              0        0        0  \n",
       "...          ...      ...      ...  \n",
       "1630162        0        0        1  \n",
       "1630163        0        0        1  \n",
       "1630164        0        0        1  \n",
       "1630165        0        0        1  \n",
       "1630166        0        0        0  \n",
       "\n",
       "[1428283 rows x 11 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sensitive_group_cols # for e.g. row with index 1 has two groups active SEX_2 and RAC1P_1, this means the person is a white female"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code block below finds the best squared loss in hindsight for\n",
    "each group subsequence by using BestLS_Hindsight class defined in **bestLS_hindsight.py**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestsqloss_list = [] #bestsqloss_list stores BestLS_Hindsight objects, can try to do multiprocessing\n",
    "for gname in gnames:\n",
    "    print(gname)\n",
    "    df_group = df_all.loc[df_all[gname] == 1] #picking only those rows where group ``gname'' is active\n",
    "    X_df_group = 1.0 * df_group.drop('PINCP', axis=1) # We're multiplying by 1.0 to make boolean False/True to 0/1\n",
    "    y_df_group = pd.DataFrame(df_group['PINCP'])\n",
    "    bestsqloss_list.append(BestLS_Hindsight(X_df_group, y_df_group))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) **pickle dump bestsqloss_list**, to be used by plitting notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('bestsqloss_hindsight_all.pkl', 'wb') as f:\n",
    "    pickle.dump(bestsqloss_list, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = A_tarr.shape[1] # number of meta-experts\n",
    "d = len(X_dat.columns) # dimensionality of features\n",
    "T = len(X_dat) # number of rounds of interaction, basically # of rows of data\n",
    "print(N, d, T)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Below we instantiate **Adanormal_sleepingexps** object from **lean_adahedge.py**, it takes as input the number of experts N, and a list of meta-experts\n",
    "\n",
    "The meta-experts here are **River_OLS** objects from **OnlineRidgeRiver.py**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experts = [River_OnlineRidge() for _ in range(N)] #online ridge meta-experts\n",
    "\n",
    "Anh = Adanormal_sleepingexps(N, experts) #adanormal hedge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ONLINE INTERACTIONS!\n",
    "for t in tqdm(range(T)): \n",
    "  Anh.get_prob_over_experts(A_tarr[t]) #get probability over meta-experts\n",
    "  Anh.update_metaexps_loss(A_tarr[t], X_dat.iloc[[t]], y_dat.iloc[t]) # update internal states of the meta-experts"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading previously saved data and building cumulative loss curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Anh.build_cumloss_curve(bestsqloss_arr, A_tarr) # Very important for plotting, calculates regret on each subsequence for Adanormal hedge"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b) Pickle dump Adanormal hedge object, to be used by the plotting notebook**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Anh_all_with_cumreg.pkl', 'wb') as f: # \"wb\" because we want to write in binary mode\n",
    "    pickle.dump(Anh, f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code cell below calculates regret of Adanormal hedge on each subsequence\n",
    "\n",
    "Essentially it calculates the: Adanormal hedge loss - bestsqloss(Least squares),for each subsequence"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code block below is a single online ridge learner which is **active in each round**\n",
    "\n",
    "We will also calculate its regret **wrt to best squared loss** on that subsequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO data structure/wrapper for the below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_oridge_baseline = linear_model.LinearRegression(l2 = 1.0) # (Kakade and Foster reference) ridge has a regret bound\n",
    "loss_tarr = []\n",
    "\n",
    "for t in tqdm(range(T)):\n",
    "    y_temp_ridge = np.clip(model_oridge_baseline.predict_many(X_dat.iloc[[t]]).iloc[0], 0.0, 1.0)\n",
    "    model_oridge_baseline.learn_many(X_dat.iloc[[t]], y_dat.iloc[t])\n",
    "    loss_tarr.append((y_temp_ridge - y_dat.iloc[t][0])**2)\n",
    "\n",
    "loss_groupwise_oridge = []\n",
    "cumloss_groupwise_oridge = []\n",
    "cumreg_groupwise_oridge = []\n",
    "loss_oridge_tarr = np.array(loss_tarr)\n",
    "\n",
    "for gnum in range(N): # build cumulative loss for  on each group subsequence\n",
    "    loss_groupwise_oridge.append(loss_oridge_tarr[A_tarr[:, gnum].astype(bool)]) # select those losses where group gnum active\n",
    "    cumloss_groupwise_oridge.append(np.cumsum(loss_groupwise_oridge[-1])) #cumulative sum of the previous\n",
    "    cumreg_groupwise_oridge.append(cumloss_groupwise_oridge[-1] - np.array(bestsqloss_arr[gnum])) #bestsquare loss for that group subsequence still the same\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1428283 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1428283/1428283 [07:30<00:00, 3167.71it/s]\n"
     ]
    }
   ],
   "source": [
    "#wrapper for above, sending dropped columns dataframe\n",
    "or_alwaysactive_dropped = OnlineRidgeImplementable_alwaysactive(X_dat_dropped, y_dat) # undropped columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('oridge_alwaysactive_droppedobj.pkl', 'wb') as f:\n",
    "    pickle.dump(or_alwaysactive_dropped, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dat_dropped = X_dat.drop(gnames, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dat_dropped"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**c) Pickle dump online ridge model and its loss_tarr** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('model_oridge_all_alwaysactive.pkl', 'wb') as f:\n",
    "    pickle.dump(model_oridge_baseline, f)\n",
    "\n",
    "with open('loss_oridge_all_alwaysactive.pkl', 'wb') as f:\n",
    "    pickle.dump(loss_tarr, f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Anh with an extra always active group**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(A_tarr.shape) # has the 11 groups already, now to add the always active group\n",
    "sensitive_group_cols = X_dat[gnames]\n",
    "sensitive_group_cols['always_on'] = 1\n",
    "A_tarr_plus = sensitive_group_cols.to_numpy()\n",
    "print(A_tarr_plus.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_tarr_plus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = A_tarr_plus.shape[1] # number of meta-experts\n",
    "d = len(X_dat.columns) # dimensionality of features\n",
    "T = len(X_dat) # number of rounds of interaction, basically # of rows of data\n",
    "print(N, d, T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experts_plusone = [River_OnlineRidge() for _ in range(N)] #online ridge meta-experts\n",
    "Anh_plusone = Adanormal_sleepingexps(N, experts_plusone) #adanormal hedge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ONLINE INTERACTIONS!\n",
    "for t in tqdm(range(T)):\n",
    "  Anh_plusone.get_prob_over_experts(A_tarr_plus[t]) #get probability over meta-experts\n",
    "  Anh_plusone.update_metaexps_loss(A_tarr_plus[t], X_dat.iloc[[t]], y_dat.iloc[t]) # update internal states of the meta-experts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Anh_plus_alwaysactive.pkl', 'wb') as f:\n",
    "    pickle.dump(Anh_plusone, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestsqloss_always_active = BestLS_Hindsight(X_dat, y_dat) #calculating best sq loss in hindsight for always active also:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('bestsqloss_alwaysactive.pkl', 'wb') as f:\n",
    "    pickle.dump(bestsqloss_always_active, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('bestsqloss_hindsight_all.pkl', 'rb') as f: #best least squares loss for each subsequence\n",
    "    bestsqloss_list = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestsqloss_list.append(bestsqloss_always_active)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('bestsqlosslist_11groups_plusalwaysactive.pkl', 'wb') as f:\n",
    "    pickle.dump(bestsqloss_list, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(bestsqloss_list[4].loss_tarr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dat"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing module, now feed only non sensitive data, i.e. drop columns with sex, race; will be understood by A_tarr_plusone\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dat_dropped = X_dat.drop(gnames, axis=1)\n",
    "# y_dat_dropped = y_dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dat_dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = A_tarr_plus.shape[1] # number of meta-experts\n",
    "d = len(X_dat_dropped.columns) # dimensionality of features\n",
    "T = len(X_dat) # number of rounds of interaction, basically # of rows of data\n",
    "print(N, d, T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experts_plusone_dropped = [River_OnlineRidge() for _ in range(N)] #online ridge meta-experts\n",
    "Anh_plusone_dropped = Adanormal_sleepingexps(N, experts_plusone_dropped) #adanormal hedge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ONLINE INTERACTIONS!\n",
    "for t in tqdm(range(T)):\n",
    "  Anh_plusone_dropped.get_prob_over_experts(A_tarr_plus[t]) #get probability over meta-experts\n",
    "  Anh_plusone_dropped.update_metaexps_loss(A_tarr_plus[t], X_dat_dropped.iloc[[t]], y_dat.iloc[t]) # update internal states of the meta-experts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Anh_plus_alwaysactive_dropped.pkl', 'wb') as f:\n",
    "    pickle.dump(Anh_plusone_dropped, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# even recomputing best squared loss in hindisght with subsequences dropped columns\n",
    "bls_together = BestLS_Hindsight_Together(N)\n",
    "for t in tqdm(range(T)):\n",
    "  bls_together.update(A_tarr_plus[t], X_dat_dropped.iloc[[t]], y_dat.iloc[t])\n",
    "# bls_together.make_all_numpyarr()\n",
    "# bls_together.cumbestsqloss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for gnum in range(N):\n",
    "    bls_together.loss_experts_arr[gnum] = np.array(bls_together.loss_experts_arr[gnum])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(bls_together.loss_experts_arr[4].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "joblib.dump(bls_together, 'bls_together_joblib.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('bls_together_plusone_dropped.pkl', 'wb') as f:\n",
    "#     pickle.dump(bls_together, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bls_together_undropped = BestLS_Hindsight_Together(N) # this is just to compare to the earlier best square loss which might take longer as it loads dataframes seperately\n",
    "for t in tqdm(range(T)):\n",
    "  bls_together_undropped.update(A_tarr_plus[t], X_dat.iloc[[t]], y_dat.iloc[t])\n",
    "# bls_together_undropped.cumbestsqloss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for gnum in range(N):\n",
    "    bls_together_undropped.loss_experts_arr[gnum] = np.array(bls_together_undropped.loss_experts_arr[gnum])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bls_together_undropped.make_all_numpyarr()\n",
    "bls_together_undropped.cumbestsqloss()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "joblib.dump(bls_together_undropped, 'bls_together_undroppedjoblib.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('bls_together_plusone_undropped.pkl', 'wb') as f:\n",
    "    pickle.dump(bls_together_undropped, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "multigroup",
   "language": "python",
   "name": "multigroup"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
