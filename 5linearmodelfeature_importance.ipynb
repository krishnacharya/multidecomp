{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from folktables import ACSDataSource\n",
    "import folktables\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import pickle\n",
    "from collections import defaultdict\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from tqdm import tqdm\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "\n",
    "import numpy as np\n",
    "from bestLS_hindsight import *\n",
    "from OnlineRidgeRiver import *\n",
    "from lean_adahedge import *\n",
    "import matplotlib.pyplot as plt\n",
    "from bestLS_hindsight_together import *\n",
    "from oridge_alwaysactive_implementable import *\n",
    "\n",
    "\n",
    "from folktables.load_acs import state_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = pd.read_pickle(\"allstates2021.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AGEP</th>\n",
       "      <th>WKHP</th>\n",
       "      <th>PINCP</th>\n",
       "      <th>COW_1</th>\n",
       "      <th>COW_2</th>\n",
       "      <th>COW_3</th>\n",
       "      <th>COW_4</th>\n",
       "      <th>COW_5</th>\n",
       "      <th>COW_6</th>\n",
       "      <th>COW_7</th>\n",
       "      <th>...</th>\n",
       "      <th>SEX_2</th>\n",
       "      <th>RAC1P_1</th>\n",
       "      <th>RAC1P_2</th>\n",
       "      <th>RAC1P_3</th>\n",
       "      <th>RAC1P_4</th>\n",
       "      <th>RAC1P_5</th>\n",
       "      <th>RAC1P_6</th>\n",
       "      <th>RAC1P_7</th>\n",
       "      <th>RAC1P_8</th>\n",
       "      <th>RAC1P_9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.025316</td>\n",
       "      <td>0.295918</td>\n",
       "      <td>0.039472</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.037975</td>\n",
       "      <td>0.397959</td>\n",
       "      <td>0.030967</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.025316</td>\n",
       "      <td>0.173469</td>\n",
       "      <td>0.030467</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.215190</td>\n",
       "      <td>0.051020</td>\n",
       "      <td>0.053479</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.025316</td>\n",
       "      <td>0.091837</td>\n",
       "      <td>0.009455</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1630162</th>\n",
       "      <td>0.291139</td>\n",
       "      <td>0.397959</td>\n",
       "      <td>0.399670</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1630163</th>\n",
       "      <td>0.379747</td>\n",
       "      <td>0.397959</td>\n",
       "      <td>0.299615</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1630164</th>\n",
       "      <td>0.367089</td>\n",
       "      <td>0.397959</td>\n",
       "      <td>0.092501</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1630165</th>\n",
       "      <td>0.063291</td>\n",
       "      <td>0.295918</td>\n",
       "      <td>0.060483</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1630166</th>\n",
       "      <td>0.493671</td>\n",
       "      <td>0.397959</td>\n",
       "      <td>0.138026</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1428283 rows × 301 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             AGEP      WKHP     PINCP  COW_1  COW_2  COW_3  COW_4  COW_5  \\\n",
       "0        0.025316  0.295918  0.039472      0      1      0      0      0   \n",
       "1        0.037975  0.397959  0.030967      1      0      0      0      0   \n",
       "2        0.025316  0.173469  0.030467      0      1      0      0      0   \n",
       "3        0.215190  0.051020  0.053479      0      1      0      0      0   \n",
       "4        0.025316  0.091837  0.009455      1      0      0      0      0   \n",
       "...           ...       ...       ...    ...    ...    ...    ...    ...   \n",
       "1630162  0.291139  0.397959  0.399670      1      0      0      0      0   \n",
       "1630163  0.379747  0.397959  0.299615      0      1      0      0      0   \n",
       "1630164  0.367089  0.397959  0.092501      0      0      0      1      0   \n",
       "1630165  0.063291  0.295918  0.060483      0      0      0      0      0   \n",
       "1630166  0.493671  0.397959  0.138026      0      1      0      0      0   \n",
       "\n",
       "         COW_6  COW_7  ...  SEX_2  RAC1P_1  RAC1P_2  RAC1P_3  RAC1P_4  \\\n",
       "0            0      0  ...      1        1        0        0        0   \n",
       "1            0      0  ...      0        0        1        0        0   \n",
       "2            0      0  ...      1        1        0        0        0   \n",
       "3            0      0  ...      1        1        0        0        0   \n",
       "4            0      0  ...      0        1        0        0        0   \n",
       "...        ...    ...  ...    ...      ...      ...      ...      ...   \n",
       "1630162      0      0  ...      1        0        0        0        0   \n",
       "1630163      0      0  ...      0        0        0        0        0   \n",
       "1630164      0      0  ...      1        0        0        0        0   \n",
       "1630165      1      0  ...      0        0        0        0        0   \n",
       "1630166      0      0  ...      1        0        1        0        0   \n",
       "\n",
       "         RAC1P_5  RAC1P_6  RAC1P_7  RAC1P_8  RAC1P_9  \n",
       "0              0        0        0        0        0  \n",
       "1              0        0        0        0        0  \n",
       "2              0        0        0        0        0  \n",
       "3              0        0        0        0        0  \n",
       "4              0        0        0        0        0  \n",
       "...          ...      ...      ...      ...      ...  \n",
       "1630162        0        0        0        0        1  \n",
       "1630163        0        0        0        0        1  \n",
       "1630164        0        0        0        0        1  \n",
       "1630165        0        0        0        0        1  \n",
       "1630166        0        0        0        0        0  \n",
       "\n",
       "[1428283 rows x 301 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dat = df_all.drop('PINCP', axis=1) #dropping the income column\n",
    "y_dat = pd.DataFrame(df_all['PINCP']) # picking up only the income column for the target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_importance(weights, feature_names):\n",
    "    '''\n",
    "        Returns a dictionary with importance for each feature (one hot encoded ones are mapped back to a single feautere)\n",
    "    '''\n",
    "    di_imp = defaultdict(int)\n",
    "    for w, name in zip(weights, feature_names):\n",
    "        fn_snip = name.split('_')[0] # if underscore wasn't there just picks the name, otherwise splits acc to underscore and picks first\n",
    "        di_imp[fn_snip] += w**2 # absolute value of weight added\n",
    "    return di_imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lr = LinearRegression(n_jobs = -1) # use all cores to build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression(n_jobs=-1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression(n_jobs=-1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression(n_jobs=-1)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_lr.fit(X_dat , y_dat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.48367663299831687"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_lr.score(X_dat, y_dat) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.48367663299831687\n"
     ]
    }
   ],
   "source": [
    "y_pred = model_lr.predict(X_dat) \n",
    "print(r2_score(y_dat, y_pred)) #0.48 R2 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Ridge()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Ridge</label><div class=\"sk-toggleable__content\"><pre>Ridge()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "Ridge()"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_ridge = Ridge() # default alpha is 1.0\n",
    "model_ridge.fit(X_dat , y_dat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4836814544979555"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_ridge.score(X_dat, y_dat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = model_lr.coef_.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "di_imp = get_feature_importance(weights, X_dat.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int,\n",
       "            {'AGEP': 0.03513697546490057,\n",
       "             'WKHP': 0.13291193431037376,\n",
       "             'COW': 1.046698411799209e+16,\n",
       "             'SCHL': 66451018516.78597,\n",
       "             'MAR': 3.637861570874854e+16,\n",
       "             'OCCP': 1.4613010604946746e+21,\n",
       "             'SEX': 1.048501153268975e+20,\n",
       "             'RAC1P': 1.1329847230447944e+20})"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "di_imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, OrdinalEncoder, TargetEncoder, StandardScaler, OneHotEncoder\n",
    "def numeric_scaler(df, cols):\n",
    "    '''\n",
    "    df: pandas dataframe\n",
    "    numeric_cols: (array of strings) column names for numeric variables\n",
    "\n",
    "    no return: does inplace operation\n",
    "    '''\n",
    "    df_new = df.copy()\n",
    "    mmscaler = MinMaxScaler()\n",
    "    df_new[cols] = mmscaler.fit_transform(df_new[cols])\n",
    "    return df_new\n",
    "\n",
    "def ordinal_encoder(df, cols): # similar to label encoder which only works for targets?\n",
    "    '''\n",
    "    Encode categorical into 0 ... n-1\n",
    "    '''\n",
    "    df_new = df.copy()\n",
    "    ordinal_enc = OrdinalEncoder()\n",
    "    df_new[cols] = ordinal_enc.fit_transform(df_new[cols])\n",
    "    return df_new\n",
    "\n",
    "def oh_sklearn(df, cols):\n",
    "    pass\n",
    "    # Issues with this operation as it doesnt preseve number of columns etc, the dummies method below works\n",
    "    # df_new = df.copy()\n",
    "    # oh_enc = OneHotEncoder()\n",
    "    # df_new[cols] = oh_enc.fit_transform(df_new[cols])\n",
    "    # return df_new\n",
    "\n",
    "def one_hot(df, cols): # idk if sklearns one-hot encoder is similar\n",
    "    \"\"\"\n",
    "    df: pandas DataFrame\n",
    "    param: cols a list of columns to encode \n",
    "    return a DataFrame with one-hot encoding\n",
    "    \"\"\"\n",
    "    for each in cols:\n",
    "        dummies = pd.get_dummies(df[each], prefix=each, drop_first=False)\n",
    "        df = pd.concat([df, dummies], axis=1)\n",
    "    return df\n",
    "\n",
    "def target_encoder(df, x_cols, y_col):\n",
    "    df_new = df.copy()\n",
    "    enc_auto = TargetEncoder(smooth=\"auto\", target_type=\"continuous\")\n",
    "    df_new[x_cols] = enc_auto.fit_transform(df_new[x_cols], df[y_col])\n",
    "    return df_new\n",
    "\n",
    "def target_encoder2(df, x_cols, y_col):\n",
    "    df_new = df.copy()\n",
    "    enc_auto = TargetEncoder(smooth=\"auto\", target_type=\"continuous\")\n",
    "    df_new[x_cols] = enc_auto.fit_transform(df_new[x_cols], df[y_col])\n",
    "    return df_new, enc_auto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected states:  ['AL', 'AK', 'AZ', 'AR', 'CA', 'CO', 'CT', 'DE', 'FL', 'GA', 'HI', 'ID', 'IL', 'IN', 'IA', 'KS', 'KY', 'LA', 'ME', 'MD', 'MA', 'MI', 'MN', 'MS', 'MO', 'MT', 'NE', 'NV', 'NH', 'NJ', 'NM', 'NY', 'NC', 'ND', 'OH', 'OK', 'OR', 'PA', 'RI', 'SC', 'SD', 'TN', 'TX', 'UT', 'VT', 'VA', 'WA', 'WV', 'WI', 'WY', 'PR']\n"
     ]
    }
   ],
   "source": [
    "# testing on non one hot encoded\n",
    "\n",
    "ACSIncome = folktables.BasicProblem(\n",
    "    features=[\n",
    "#         'ST',\n",
    "        'AGEP', #Numeric, age of householder\n",
    "        'COW',  #Categorical, class of worker \n",
    "        'SCHL', #Categorical, educational attainment\n",
    "        'MAR', #Categorical, Mamarital status 5 categories \n",
    "        'OCCP', #Categorical, occupation lots of codes here\n",
    "#         'POBP', #place of birth, US states, and if international has places\n",
    "#         'RELSHIPP', #Relationship, renamed to Relantioship in the new PUMS syntax, 20 - 38\n",
    "        'WKHP', #Numeric, hours worked per week in last 12 months\n",
    "        'SEX',  #Categorical Male, Female 2 \n",
    "        'RAC1P', #Categorical Recoded detailed race code, 9 categories here 1)White ... 9\n",
    "    ],\n",
    "    target='PINCP',\n",
    "    group = 'RAC1P', #ignore this flag\n",
    "    preprocess=folktables.adult_filter, # age of householder > 16, etc.., see acs.py in folktables\n",
    "    postprocess=lambda x: np.nan_to_num(x, -1),\n",
    ") #default ACSIncome Pull above\n",
    "\n",
    "# random.seed(42) not shuffling, state wise round robin, kind of non-stochastic setting\n",
    "# random.shuffle(state_list)\n",
    "print('Selected states: ', state_list)\n",
    "data_source = ACSDataSource(survey_year='2021', horizon='1-Year', survey='person')\n",
    "acs_data = data_source.get_data(state_list, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, gr = ACSIncome.df_to_pandas(acs_data)\n",
    "dataset = pd.concat([X, y], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AGEP</th>\n",
       "      <th>COW</th>\n",
       "      <th>SCHL</th>\n",
       "      <th>MAR</th>\n",
       "      <th>OCCP</th>\n",
       "      <th>WKHP</th>\n",
       "      <th>SEX</th>\n",
       "      <th>RAC1P</th>\n",
       "      <th>PINCP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4760.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4640.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5240.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4220.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2722.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1630162</th>\n",
       "      <td>40.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1430.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>80000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1630163</th>\n",
       "      <td>47.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2205.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>60000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1630164</th>\n",
       "      <td>46.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5740.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>18600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1630165</th>\n",
       "      <td>22.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2634.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>12200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1630166</th>\n",
       "      <td>56.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2300.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>27700.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1630167 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         AGEP  COW  SCHL  MAR    OCCP  WKHP  SEX  RAC1P    PINCP\n",
       "0        19.0  2.0  18.0  5.0  4760.0  30.0  2.0    1.0   8000.0\n",
       "1        20.0  1.0  19.0  5.0  4640.0  40.0  1.0    2.0   6300.0\n",
       "2        19.0  2.0  18.0  5.0  5240.0  18.0  2.0    1.0   6200.0\n",
       "3        34.0  2.0  19.0  3.0  4220.0   6.0  2.0    1.0  10800.0\n",
       "4        19.0  1.0  18.0  5.0  2722.0  10.0  1.0    1.0   2000.0\n",
       "...       ...  ...   ...  ...     ...   ...  ...    ...      ...\n",
       "1630162  40.0  1.0  21.0  5.0  1430.0  40.0  2.0    9.0  80000.0\n",
       "1630163  47.0  2.0  22.0  1.0  2205.0  40.0  1.0    9.0  60000.0\n",
       "1630164  46.0  4.0  21.0  1.0  5740.0  40.0  2.0    9.0  18600.0\n",
       "1630165  22.0  6.0  21.0  5.0  2634.0  30.0  1.0    9.0  12200.0\n",
       "1630166  56.0  2.0  21.0  1.0  2300.0  40.0  2.0    2.0  27700.0\n",
       "\n",
       "[1630167 rows x 9 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#important to explicity define columns with categoricals as ints to index properly into them\n",
    "dataset['COW'] = dataset['COW'].astype(int)\n",
    "dataset['SCHL'] = dataset['SCHL'].astype(int)\n",
    "dataset['MAR'] = dataset['MAR'].astype(int)\n",
    "dataset['OCCP'] = dataset['OCCP'].astype(int)\n",
    "dataset['SEX'] = dataset['SEX'].astype(int)\n",
    "dataset['RAC1P'] = dataset['RAC1P'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8761574734367706\n"
     ]
    }
   ],
   "source": [
    "data_incomeless200k = dataset[dataset['PINCP'] <= 2e5]\n",
    "top_200OCCP = dataset['OCCP'].value_counts()[:250].index.tolist() # top 200 occupation codes in the original dataframe\n",
    "data_fil = data_incomeless200k[data_incomeless200k['OCCP'].isin(top_200OCCP)]\n",
    "print(len(data_fil) / len(dataset)) #top200 occp codes and <= 200k is 83 % of original dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7999997199434565"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df_fil_train, df_fil_test = train_test_split(data_fil, test_size=0.2)\n",
    "\n",
    "# df_fil_train, df_fil_test\n",
    "# len(df_fil_train)/ (len(df_fil_train) + len(df_fil_test)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/krisacha/anaconda3/envs/multigroup/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR score on target encoding and scaled 0.4656838691354256\n",
      "Ridge score on target encoding and scaled 0.46568386895596003\n",
      "Lasso score on target encoding and scaled 0.0\n"
     ]
    }
   ],
   "source": [
    "# target encodings followed by minmax scaling all, just using TRAIN DATA\n",
    "categorical_cols = ['COW','SCHL', 'MAR', 'OCCP', 'SEX', 'RAC1P']\n",
    "df_te, te_trfit = target_encoder2(df_fil_train, categorical_cols, ['PINCP']) # returns modified dataframe as well as target encoder object which has learnt the transformation\n",
    "df_te_scaled = numeric_scaler(df_te, df_te.columns)\n",
    "\n",
    "# df_te_scaled.head()\n",
    "\n",
    "X_dat_te_scaled = df_te_scaled.drop('PINCP', axis=1) #dropping the income column\n",
    "y_dat_te_scaled = pd.DataFrame(df_te_scaled['PINCP']) # picking up only the income column for the target\n",
    "\n",
    "model_lr_te_scaled = LinearRegression(n_jobs = -1)\n",
    "model_lr_te_scaled.fit(X_dat_te_scaled, y_dat_te_scaled)\n",
    "print(f\"LR score on target encoding and scaled {model_lr_te_scaled.score(X_dat_te_scaled, y_dat_te_scaled)}\")\n",
    "\n",
    "model_ridge_te_scaled = Ridge()\n",
    "model_ridge_te_scaled.fit(X_dat_te_scaled, y_dat_te_scaled)\n",
    "print(f\"Ridge score on target encoding and scaled {model_ridge_te_scaled.score(X_dat_te_scaled, y_dat_te_scaled)}\")\n",
    "\n",
    "model_lasso_te_scaled = Lasso() # kinda garbage , all zeros for weight?\n",
    "model_lasso_te_scaled.fit(X_dat_te_scaled, y_dat_te_scaled)\n",
    "print(f\"Lasso score on target encoding and scaled {model_lasso_te_scaled.score(X_dat_te_scaled, y_dat_te_scaled)}\")\n",
    "\n",
    "#TODO try r2 scores on some unseen data, using transform, dont do fit transform from target_encoder!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR score on target encoding and scaled 0.4662467793371893\n"
     ]
    }
   ],
   "source": [
    "df_te_test = df_fil_test.copy()\n",
    "df_te_test[categorical_cols] = te_trfit.transform(df_te_test[categorical_cols]) # using target encoder fitted on df_fil_train\n",
    "df_test_te_scaled = numeric_scaler(df_te_test, df_te_test.columns)\n",
    "\n",
    "X_dat_test_te_scaled = df_test_te_scaled.drop('PINCP', axis=1) #dropping the income column\n",
    "y_dat_test_te_scaled = pd.DataFrame(df_test_te_scaled['PINCP']) # picking up only the income column for the target\n",
    "\n",
    "model_lr_test_te_scaled = LinearRegression(n_jobs = -1)\n",
    "model_lr_test_te_scaled.fit(X_dat_test_te_scaled, y_dat_test_te_scaled)\n",
    "print(f\"LR score on target encoding and scaled {model_lr_test_te_scaled.score(X_dat_test_te_scaled, y_dat_test_te_scaled)}\") #good r2 score on test too!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AGEP</th>\n",
       "      <th>COW</th>\n",
       "      <th>SCHL</th>\n",
       "      <th>MAR</th>\n",
       "      <th>OCCP</th>\n",
       "      <th>WKHP</th>\n",
       "      <th>SEX</th>\n",
       "      <th>RAC1P</th>\n",
       "      <th>PINCP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1139538</th>\n",
       "      <td>0.217949</td>\n",
       "      <td>0.570100</td>\n",
       "      <td>0.982866</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.485006</td>\n",
       "      <td>0.397959</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.721492</td>\n",
       "      <td>0.254090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310829</th>\n",
       "      <td>0.243590</td>\n",
       "      <td>0.570100</td>\n",
       "      <td>0.255286</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.057917</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.721492</td>\n",
       "      <td>0.057982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204117</th>\n",
       "      <td>0.448718</td>\n",
       "      <td>0.570100</td>\n",
       "      <td>0.303277</td>\n",
       "      <td>0.696557</td>\n",
       "      <td>0.536642</td>\n",
       "      <td>0.551020</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.721492</td>\n",
       "      <td>0.349642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1074027</th>\n",
       "      <td>0.679487</td>\n",
       "      <td>0.570100</td>\n",
       "      <td>0.812543</td>\n",
       "      <td>0.696557</td>\n",
       "      <td>0.317940</td>\n",
       "      <td>0.448980</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.165465</td>\n",
       "      <td>0.958977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452676</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.570100</td>\n",
       "      <td>0.411967</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.503323</td>\n",
       "      <td>0.397959</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.721492</td>\n",
       "      <td>0.524739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>810867</th>\n",
       "      <td>0.512821</td>\n",
       "      <td>0.862932</td>\n",
       "      <td>0.411967</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.815653</td>\n",
       "      <td>0.602041</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.721492</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235738</th>\n",
       "      <td>0.512821</td>\n",
       "      <td>0.570100</td>\n",
       "      <td>0.303277</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.574038</td>\n",
       "      <td>0.061224</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.721492</td>\n",
       "      <td>0.013958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1540486</th>\n",
       "      <td>0.589744</td>\n",
       "      <td>0.653125</td>\n",
       "      <td>0.640085</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.468525</td>\n",
       "      <td>0.234694</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.721492</td>\n",
       "      <td>0.509730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1061370</th>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.570100</td>\n",
       "      <td>0.303277</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.685173</td>\n",
       "      <td>0.397959</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.721492</td>\n",
       "      <td>0.202061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1045124</th>\n",
       "      <td>0.051282</td>\n",
       "      <td>0.570100</td>\n",
       "      <td>0.268890</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.193522</td>\n",
       "      <td>0.193878</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.721492</td>\n",
       "      <td>0.024463</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>285657 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             AGEP       COW      SCHL       MAR      OCCP      WKHP  SEX  \\\n",
       "1139538  0.217949  0.570100  0.982866  0.000000  0.485006  0.397959  0.0   \n",
       "310829   0.243590  0.570100  0.255286  0.000000  0.057917  0.214286  1.0   \n",
       "204117   0.448718  0.570100  0.303277  0.696557  0.536642  0.551020  1.0   \n",
       "1074027  0.679487  0.570100  0.812543  0.696557  0.317940  0.448980  1.0   \n",
       "452676   0.500000  0.570100  0.411967  1.000000  0.503323  0.397959  0.0   \n",
       "...           ...       ...       ...       ...       ...       ...  ...   \n",
       "810867   0.512821  0.862932  0.411967  1.000000  0.815653  0.602041  1.0   \n",
       "235738   0.512821  0.570100  0.303277  1.000000  0.574038  0.061224  0.0   \n",
       "1540486  0.589744  0.653125  0.640085  1.000000  0.468525  0.234694  0.0   \n",
       "1061370  0.166667  0.570100  0.303277  1.000000  0.685173  0.397959  1.0   \n",
       "1045124  0.051282  0.570100  0.268890  0.000000  0.193522  0.193878  1.0   \n",
       "\n",
       "            RAC1P     PINCP  \n",
       "1139538  0.721492  0.254090  \n",
       "310829   0.721492  0.057982  \n",
       "204117   0.721492  0.349642  \n",
       "1074027  0.165465  0.958977  \n",
       "452676   0.721492  0.524739  \n",
       "...           ...       ...  \n",
       "810867   0.721492  1.000000  \n",
       "235738   0.721492  0.013958  \n",
       "1540486  0.721492  0.509730  \n",
       "1061370  0.721492  0.202061  \n",
       "1045124  0.721492  0.024463  \n",
       "\n",
       "[285657 rows x 9 columns]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_te_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "te_trfit.transform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.37049427559931525"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_dat_acs = data_fil.drop('PINCP', axis=1) #dropping the income column\n",
    "y_dat_acs = pd.DataFrame(data_fil['PINCP']) # picking up only the income column for the target\n",
    "# just using the default encodings given in dataset, NOT Even scaled\n",
    "model_lr_acs = LinearRegression(n_jobs = -1) # use all cores to build model\n",
    "model_lr_acs.fit(X_dat_acs, y_dat_acs)\n",
    "model_lr_acs.score(X_dat_acs, y_dat_acs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3704942755993147"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scaling all og encodings of acs using numeric scaler, almost same r2 score as above\n",
    "df_acsencodings_scaled = numeric_scaler(data_fil, data_fil.columns)\n",
    "X_dat_acs_scaled = df_acsencodings_scaled.drop('PINCP', axis=1) #dropping the income column\n",
    "y_dat_acs_scaled = pd.DataFrame(df_acsencodings_scaled['PINCP']) # picking up only the income column for the target\n",
    "\n",
    "model_lr_acs_scaled = LinearRegression(n_jobs = -1)\n",
    "model_lr_acs_scaled.fit(X_dat_acs_scaled, y_dat_acs_scaled)\n",
    "model_lr_acs_scaled.score(X_dat_acs_scaled, y_dat_acs_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.37505966799974755"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ordinal encoding of categoric followed by minmax scaling of all columns\n",
    "# using ordinal encodings for categorical, then minmax scaling all, not principled but anyway.., minute bump in r2 score\n",
    "categorical_cols = ['COW','SCHL', 'MAR', 'OCCP', 'SEX', 'RAC1P']\n",
    "df_ordinal = ordinal_encoder(data_fil, categorical_cols)\n",
    "df_ordinal_scaled = numeric_scaler(df_ordinal, df_ordinal.columns) # scaling all columns here\n",
    "\n",
    "X_dat_ord_allscaled = df_ordinal_scaled.drop('PINCP', axis=1) #dropping the income column\n",
    "y_dat_ord_allscaled = pd.DataFrame(df_ordinal_scaled['PINCP']) # picking up only the income column for the target\n",
    "\n",
    "\n",
    "model_lr_ordinal_allscaled = LinearRegression(n_jobs = -1)\n",
    "model_lr_ordinal_allscaled.fit(X_dat_ord_allscaled, y_dat_ord_allscaled)\n",
    "model_lr_ordinal_allscaled.score(X_dat_ord_allscaled, y_dat_ord_allscaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AGEP</th>\n",
       "      <th>COW</th>\n",
       "      <th>SCHL</th>\n",
       "      <th>MAR</th>\n",
       "      <th>OCCP</th>\n",
       "      <th>WKHP</th>\n",
       "      <th>SEX</th>\n",
       "      <th>RAC1P</th>\n",
       "      <th>PINCP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19.0</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>5</td>\n",
       "      <td>4760</td>\n",
       "      <td>30.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>8000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.0</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>5</td>\n",
       "      <td>4640</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.0</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>5</td>\n",
       "      <td>5240</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>6200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34.0</td>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "      <td>3</td>\n",
       "      <td>4220</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>10800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19.0</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>5</td>\n",
       "      <td>2722</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1630162</th>\n",
       "      <td>40.0</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>5</td>\n",
       "      <td>1430</td>\n",
       "      <td>40.0</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>80000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1630163</th>\n",
       "      <td>47.0</td>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>2205</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>60000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1630164</th>\n",
       "      <td>46.0</td>\n",
       "      <td>4</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>5740</td>\n",
       "      <td>40.0</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>18600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1630165</th>\n",
       "      <td>22.0</td>\n",
       "      <td>6</td>\n",
       "      <td>21</td>\n",
       "      <td>5</td>\n",
       "      <td>2634</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>12200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1630166</th>\n",
       "      <td>56.0</td>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>2300</td>\n",
       "      <td>40.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>27700.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1428283 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         AGEP  COW  SCHL  MAR  OCCP  WKHP  SEX  RAC1P    PINCP\n",
       "0        19.0    2    18    5  4760  30.0    2      1   8000.0\n",
       "1        20.0    1    19    5  4640  40.0    1      2   6300.0\n",
       "2        19.0    2    18    5  5240  18.0    2      1   6200.0\n",
       "3        34.0    2    19    3  4220   6.0    2      1  10800.0\n",
       "4        19.0    1    18    5  2722  10.0    1      1   2000.0\n",
       "...       ...  ...   ...  ...   ...   ...  ...    ...      ...\n",
       "1630162  40.0    1    21    5  1430  40.0    2      9  80000.0\n",
       "1630163  47.0    2    22    1  2205  40.0    1      9  60000.0\n",
       "1630164  46.0    4    21    1  5740  40.0    2      9  18600.0\n",
       "1630165  22.0    6    21    5  2634  30.0    1      9  12200.0\n",
       "1630166  56.0    2    21    1  2300  40.0    2      2  27700.0\n",
       "\n",
       "[1428283 rows x 9 columns]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_fil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/krisacha/anaconda3/envs/multigroup/lib/python3.11/site-packages/sklearn/utils/validation.py:1184: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR score on target encoding and scaled 0.4657885318923807\n",
      "Ridge score on target encoding and scaled 0.4657885317767201\n",
      "Lasso score on target encoding and scaled 0.0\n"
     ]
    }
   ],
   "source": [
    "# target encodings followed by minmax scaling all, USING Target encoder old one\n",
    "categorical_cols = ['COW','SCHL', 'MAR', 'OCCP', 'SEX', 'RAC1P']\n",
    "df_te = target_encoder(data_fil, categorical_cols, ['PINCP'])\n",
    "df_te_scaled = numeric_scaler(df_te, df_te.columns)\n",
    "\n",
    "# df_te_scaled.head()\n",
    "\n",
    "X_dat_te_scaled = df_te_scaled.drop('PINCP', axis=1) #dropping the income column\n",
    "y_dat_te_scaled = pd.DataFrame(df_te_scaled['PINCP']) # picking up only the income column for the target\n",
    "\n",
    "model_lr_te_scaled = LinearRegression(n_jobs = -1)\n",
    "model_lr_te_scaled.fit(X_dat_te_scaled, y_dat_te_scaled)\n",
    "print(f\"LR score on target encoding and scaled {model_lr_te_scaled.score(X_dat_te_scaled, y_dat_te_scaled)}\")\n",
    "\n",
    "model_ridge_te_scaled = Ridge()\n",
    "model_ridge_te_scaled.fit(X_dat_te_scaled, y_dat_te_scaled)\n",
    "print(f\"Ridge score on target encoding and scaled {model_ridge_te_scaled.score(X_dat_te_scaled, y_dat_te_scaled)}\")\n",
    "\n",
    "model_lasso_te_scaled = Lasso() # kinda garbage , all zeros for weight?\n",
    "model_lasso_te_scaled.fit(X_dat_te_scaled, y_dat_te_scaled)\n",
    "print(f\"Lasso score on target encoding and scaled {model_lasso_te_scaled.score(X_dat_te_scaled, y_dat_te_scaled)}\")\n",
    "\n",
    "#TODO try r2 scores on some unseen data, using transform, dont do fit transform from target_encoder!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_lasso_te_scaled.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AGEP</th>\n",
       "      <th>COW</th>\n",
       "      <th>SCHL</th>\n",
       "      <th>MAR</th>\n",
       "      <th>OCCP</th>\n",
       "      <th>WKHP</th>\n",
       "      <th>SEX</th>\n",
       "      <th>RAC1P</th>\n",
       "      <th>PINCP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.428283e+06</td>\n",
       "      <td>1.428283e+06</td>\n",
       "      <td>1.428283e+06</td>\n",
       "      <td>1.428283e+06</td>\n",
       "      <td>1.428283e+06</td>\n",
       "      <td>1.428283e+06</td>\n",
       "      <td>1.428283e+06</td>\n",
       "      <td>1.428283e+06</td>\n",
       "      <td>1.428283e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.318182e-01</td>\n",
       "      <td>6.010992e-01</td>\n",
       "      <td>4.396685e-01</td>\n",
       "      <td>6.171714e-01</td>\n",
       "      <td>3.493485e-01</td>\n",
       "      <td>3.744374e-01</td>\n",
       "      <td>5.047707e-01</td>\n",
       "      <td>5.979388e-01</td>\n",
       "      <td>2.533181e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.956121e-01</td>\n",
       "      <td>1.176823e-01</td>\n",
       "      <td>2.325424e-01</td>\n",
       "      <td>4.521444e-01</td>\n",
       "      <td>2.028869e-01</td>\n",
       "      <td>1.310068e-01</td>\n",
       "      <td>4.972896e-01</td>\n",
       "      <td>2.647814e-01</td>\n",
       "      <td>2.037726e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.645570e-01</td>\n",
       "      <td>5.697645e-01</td>\n",
       "      <td>2.544899e-01</td>\n",
       "      <td>9.823312e-04</td>\n",
       "      <td>1.920848e-01</td>\n",
       "      <td>3.469388e-01</td>\n",
       "      <td>2.239559e-03</td>\n",
       "      <td>3.028767e-01</td>\n",
       "      <td>9.950473e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.291139e-01</td>\n",
       "      <td>5.710511e-01</td>\n",
       "      <td>3.044830e-01</td>\n",
       "      <td>9.965160e-01</td>\n",
       "      <td>3.126735e-01</td>\n",
       "      <td>3.979592e-01</td>\n",
       "      <td>9.931332e-01</td>\n",
       "      <td>7.248884e-01</td>\n",
       "      <td>1.995598e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.936709e-01</td>\n",
       "      <td>6.498886e-01</td>\n",
       "      <td>6.360905e-01</td>\n",
       "      <td>9.981073e-01</td>\n",
       "      <td>5.005458e-01</td>\n",
       "      <td>3.979592e-01</td>\n",
       "      <td>9.965252e-01</td>\n",
       "      <td>7.271626e-01</td>\n",
       "      <td>3.496423e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               AGEP           COW          SCHL           MAR          OCCP  \\\n",
       "count  1.428283e+06  1.428283e+06  1.428283e+06  1.428283e+06  1.428283e+06   \n",
       "mean   3.318182e-01  6.010992e-01  4.396685e-01  6.171714e-01  3.493485e-01   \n",
       "std    1.956121e-01  1.176823e-01  2.325424e-01  4.521444e-01  2.028869e-01   \n",
       "min    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "25%    1.645570e-01  5.697645e-01  2.544899e-01  9.823312e-04  1.920848e-01   \n",
       "50%    3.291139e-01  5.710511e-01  3.044830e-01  9.965160e-01  3.126735e-01   \n",
       "75%    4.936709e-01  6.498886e-01  6.360905e-01  9.981073e-01  5.005458e-01   \n",
       "max    1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00   \n",
       "\n",
       "               WKHP           SEX         RAC1P         PINCP  \n",
       "count  1.428283e+06  1.428283e+06  1.428283e+06  1.428283e+06  \n",
       "mean   3.744374e-01  5.047707e-01  5.979388e-01  2.533181e-01  \n",
       "std    1.310068e-01  4.972896e-01  2.647814e-01  2.037726e-01  \n",
       "min    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  \n",
       "25%    3.469388e-01  2.239559e-03  3.028767e-01  9.950473e-02  \n",
       "50%    3.979592e-01  9.931332e-01  7.248884e-01  1.995598e-01  \n",
       "75%    3.979592e-01  9.965252e-01  7.271626e-01  3.496423e-01  \n",
       "max    1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00  "
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_te_scaled.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.15842867 0.06435285 0.15871977 0.03247738 0.37611711 0.34215615\n",
      " 0.03670554 0.02470359]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plotting weights of the Linear regression model\n",
    "print(model_lr_te_scaled.coef_.ravel())\n",
    "coefs = pd.DataFrame(\n",
    "    model_lr_te_scaled.coef_.ravel(), columns=[\"Coefficients\"], index=X_dat_te_scaled.columns\n",
    ")\n",
    "\n",
    "# most important seem to be OCCP, WKHP, SCHL, AGEP, COW\n",
    "coefs.plot(kind=\"barh\")\n",
    "plt.title(\"Ridge model\")\n",
    "plt.axvline(x=0, color=\".5\")\n",
    "plt.subplots_adjust(left=0.3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.15842172 0.06455013 0.15870555 0.03247702 0.37688302 0.34214442\n",
      " 0.03668347 0.02520665]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plotting weights of the Linear regression model\n",
    "print(model_ridge_te_scaled.coef_.ravel())\n",
    "coefs = pd.DataFrame(\n",
    "    model_ridge_te_scaled.coef_.ravel(), columns=[\"Coefficients\"], index=X_dat_te_scaled.columns\n",
    ")\n",
    "\n",
    "# most important seem to be OCCP, WKHP, SCHL, AGEP, COW\n",
    "coefs.plot(kind=\"barh\")\n",
    "plt.title(\"Ridge model\")\n",
    "plt.axvline(x=0, color=\".5\")\n",
    "plt.subplots_adjust(left=0.3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AGEP     float64\n",
       "COW        int64\n",
       "SCHL       int64\n",
       "MAR        int64\n",
       "OCCP       int64\n",
       "WKHP     float64\n",
       "SEX        int64\n",
       "RAC1P      int64\n",
       "PINCP    float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_fil.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({20.0: 41072, 240.0: 36593, 103.0: 33898, 74.0: 32040, 156.0: 31803, 158.0: 30084, 172.0: 28305, 154.0: 26846, 245.0: 26727, 187.0: 25058, 142.0: 24088, 131.0: 20294, 247.0: 18144, 197.0: 17502, 135.0: 17494, 34.0: 17264, 43.0: 16088, 72.0: 16083, 116.0: 15378, 80.0: 15074, 75.0: 14814, 190.0: 13648, 235.0: 13416, 168.0: 13368, 6.0: 13000, 178.0: 12963, 144.0: 12518, 117.0: 12127, 143.0: 11963, 195.0: 11629, 162.0: 11558, 165.0: 11487, 0.0: 10854, 1.0: 10571, 13.0: 10163, 222.0: 10101, 70.0: 9893, 149.0: 9850, 30.0: 9579, 12.0: 9568, 155.0: 9249, 163.0: 9170, 200.0: 9131, 26.0: 8963, 132.0: 8906, 192.0: 8822, 78.0: 8790, 127.0: 8776, 134.0: 8765, 232.0: 8755, 11.0: 8529, 211.0: 8321, 15.0: 8304, 191.0: 8147, 73.0: 8099, 29.0: 8071, 126.0: 7944, 216.0: 7870, 220.0: 7518, 48.0: 7293, 147.0: 7257, 17.0: 7082, 45.0: 7030, 57.0: 6557, 180.0: 6540, 193.0: 6210, 185.0: 6053, 243.0: 5975, 5.0: 5925, 227.0: 5916, 69.0: 5829, 33.0: 5822, 112.0: 5760, 67.0: 5708, 161.0: 5650, 202.0: 5643, 159.0: 5633, 121.0: 5576, 18.0: 5516, 40.0: 5515, 2.0: 5372, 246.0: 5207, 115.0: 5128, 201.0: 5047, 164.0: 4976, 19.0: 4810, 76.0: 4736, 3.0: 4713, 71.0: 4668, 96.0: 4657, 167.0: 4508, 130.0: 4453, 53.0: 4397, 58.0: 4283, 198.0: 4272, 129.0: 4245, 214.0: 4183, 215.0: 4075, 64.0: 3967, 110.0: 3887, 228.0: 3872, 32.0: 3831, 226.0: 3789, 244.0: 3708, 133.0: 3660, 60.0: 3630, 183.0: 3590, 85.0: 3580, 124.0: 3529, 95.0: 3502, 249.0: 3448, 23.0: 3434, 38.0: 3412, 56.0: 3390, 123.0: 3386, 83.0: 3345, 42.0: 3312, 238.0: 3281, 82.0: 3253, 36.0: 3242, 241.0: 3214, 105.0: 3211, 145.0: 3202, 50.0: 3193, 212.0: 3165, 139.0: 3134, 188.0: 3092, 24.0: 3018, 10.0: 2976, 120.0: 2974, 35.0: 2940, 99.0: 2921, 186.0: 2887, 87.0: 2876, 22.0: 2840, 104.0: 2809, 62.0: 2805, 8.0: 2790, 146.0: 2771, 236.0: 2765, 77.0: 2762, 184.0: 2735, 138.0: 2725, 55.0: 2688, 54.0: 2641, 91.0: 2629, 7.0: 2619, 137.0: 2603, 170.0: 2587, 151.0: 2531, 150.0: 2478, 233.0: 2439, 148.0: 2438, 175.0: 2404, 224.0: 2404, 206.0: 2397, 128.0: 2375, 68.0: 2360, 213.0: 2342, 107.0: 2339, 79.0: 2336, 47.0: 2319, 9.0: 2303, 51.0: 2267, 219.0: 2228, 248.0: 2183, 223.0: 2168, 239.0: 2159, 140.0: 2144, 102.0: 2130, 122.0: 2081, 101.0: 2076, 209.0: 2074, 86.0: 2069, 189.0: 2064, 21.0: 2017, 113.0: 2005, 66.0: 2005, 92.0: 1985, 136.0: 1977, 106.0: 1968, 203.0: 1851, 119.0: 1824, 88.0: 1797, 28.0: 1778, 81.0: 1763, 61.0: 1742, 27.0: 1733, 59.0: 1720, 169.0: 1713, 14.0: 1708, 65.0: 1704, 181.0: 1698, 49.0: 1661, 111.0: 1647, 208.0: 1591, 160.0: 1578, 41.0: 1573, 90.0: 1569, 25.0: 1562, 207.0: 1557, 237.0: 1551, 225.0: 1512, 97.0: 1498, 98.0: 1497, 229.0: 1494, 242.0: 1492, 231.0: 1484, 173.0: 1481, 141.0: 1464, 114.0: 1459, 230.0: 1429, 52.0: 1427, 177.0: 1407, 152.0: 1392, 31.0: 1383, 171.0: 1377, 234.0: 1372, 89.0: 1370, 157.0: 1360, 179.0: 1347, 194.0: 1339, 63.0: 1337, 125.0: 1325, 176.0: 1323, 46.0: 1319, 39.0: 1308, 4.0: 1304, 93.0: 1302, 100.0: 1295, 182.0: 1285, 118.0: 1268, 153.0: 1243, 210.0: 1241, 204.0: 1233, 217.0: 1205, 199.0: 1205, 16.0: 1197, 174.0: 1196, 94.0: 1193, 109.0: 1190, 205.0: 1186, 196.0: 1185, 108.0: 1181, 84.0: 1181, 221.0: 1176, 37.0: 1174, 218.0: 1138, 166.0: 1132, 44.0: 1117})\n",
      "count    1.428283e+06\n",
      "mean     1.267574e+02\n",
      "std      7.264053e+01\n",
      "min      0.000000e+00\n",
      "25%      7.000000e+01\n",
      "50%      1.350000e+02\n",
      "75%      1.860000e+02\n",
      "max      2.490000e+02\n",
      "Name: OCCP, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "print(Counter(df_ordinal['OCCP']))\n",
    "print(df_ordinal['OCCP'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_oh_check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "def numeric_scaler(df, numeric_cols):\n",
    "    '''\n",
    "    df: pandas dataframe\n",
    "    numeric_cols: (array of strings) column names for numeric variables\n",
    "\n",
    "    no return: does inplace operation\n",
    "    '''\n",
    "    numeric_scaler = MinMaxScaler()\n",
    "    df[numeric_cols] = numeric_scaler.fit_transform(df[numeric_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_cp = dataset\n",
    "numeric_scaler(dataset_cp, dataset_cp.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dat_noh = dataset_cp.drop('PINCP', axis=1) #dropping the income column\n",
    "y_dat_noh = pd.DataFrame(dataset_cp['PINCP']) # picking up only the income column for the target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.23386053772833315"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_lr_notonehot_mmscaled = LinearRegression(n_jobs = -1) # use all cores to build model\n",
    "model_lr_notonehot_mmscaled.fit(X_dat_noh, y_dat_noh)\n",
    "model_lr_notonehot_mmscaled.score(X_dat_noh, y_dat_noh)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AGEP</th>\n",
       "      <th>COW</th>\n",
       "      <th>SCHL</th>\n",
       "      <th>MAR</th>\n",
       "      <th>OCCP</th>\n",
       "      <th>WKHP</th>\n",
       "      <th>SEX</th>\n",
       "      <th>RAC1P</th>\n",
       "      <th>PINCP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4760.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4640.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5240.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4220.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2722.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1630162</th>\n",
       "      <td>40.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1430.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>80000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1630163</th>\n",
       "      <td>47.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2205.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>60000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1630164</th>\n",
       "      <td>46.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5740.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>18600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1630165</th>\n",
       "      <td>22.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2634.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>12200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1630166</th>\n",
       "      <td>56.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2300.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>27700.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1630167 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         AGEP  COW  SCHL  MAR    OCCP  WKHP  SEX  RAC1P    PINCP\n",
       "0        19.0  2.0  18.0  5.0  4760.0  30.0  2.0    1.0   8000.0\n",
       "1        20.0  1.0  19.0  5.0  4640.0  40.0  1.0    2.0   6300.0\n",
       "2        19.0  2.0  18.0  5.0  5240.0  18.0  2.0    1.0   6200.0\n",
       "3        34.0  2.0  19.0  3.0  4220.0   6.0  2.0    1.0  10800.0\n",
       "4        19.0  1.0  18.0  5.0  2722.0  10.0  1.0    1.0   2000.0\n",
       "...       ...  ...   ...  ...     ...   ...  ...    ...      ...\n",
       "1630162  40.0  1.0  21.0  5.0  1430.0  40.0  2.0    9.0  80000.0\n",
       "1630163  47.0  2.0  22.0  1.0  2205.0  40.0  1.0    9.0  60000.0\n",
       "1630164  46.0  4.0  21.0  1.0  5740.0  40.0  2.0    9.0  18600.0\n",
       "1630165  22.0  6.0  21.0  5.0  2634.0  30.0  1.0    9.0  12200.0\n",
       "1630166  56.0  2.0  21.0  1.0  2300.0  40.0  2.0    2.0  27700.0\n",
       "\n",
       "[1630167 rows x 9 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dat_noh = dataset_cp.drop('PINCP', axis=1) #dropping the income column\n",
    "y_dat_noh = pd.DataFrame(dataset_cp['PINCP']) # picking up only the income column for the target"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "multigroup",
   "language": "python",
   "name": "multigroup"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
